<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Qyrix AI - Madni Bot Voice Chat</title>
<link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;600&family=Inter&display=swap" rel="stylesheet">
<style>
* { box-sizing: border-box; margin: 0; padding: 0; }
body {
  font-family: 'Inter', sans-serif;
  background-image: url('sunrise.jpg');
  background-size: cover;
  background-position: center;
  background-repeat: no-repeat;
  color: white;
  height: 100vh;
  display: flex;
  justify-content: center;
  align-items: center;
  overflow: hidden;
}
.container {
  margin-top: 100px;
  width: 100%;
  max-width: 800px;
  height: 100vh;
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  padding: 20px;
  position: relative;
}

/* 1Ô∏è‚É£ Anime character video (e.g. 10-second loop) - always visible, plays only during TTS */
.video-wrap {
  /* position: relative; */
  width: 100%;
  /* height: 500px; */
  /* margin-bottom: 10px; */
  border-radius: 12px;
  overflow: hidden;
  /* background: #111; */
  /* border: 1px solid rgba(0, 242, 255, 0.3); */
}
#avatar-video {
  width: 100%;
  height: 100%;
  /* object-fit: cover; */
  display: block;
}
/* Warm theme: gold/amber to match sunrise & mosque ‚Äì talking pulse */
.video-wrap.talking {
  box-shadow: 0 0 28px rgba(212, 175, 55, 0.5);
  transition: box-shadow 0.1s ease-out;
}

.status {
  font-size: 16px;
  color: #000000;
  margin-bottom: 20px;
  text-align: center;
  min-height: 24px;
  font-family: 'Orbitron', sans-serif;
  text-shadow: 0 0 12px rgba(212, 175, 55, 0.4);
}
.status.listening { color: #e8b86d; }
.status.error { color: #c95a3a; font-size: 14px; }
.text-display {
  position: absolute;
  bottom: 140px;
  left: 50%;
  transform: translateX(-50%);
  width: 90%;
  max-width: 500px;
  background: rgba(30, 22, 12, 0.75);
  padding: 12px 18px;
  border-radius: 15px;
  border: 1px solid rgba(212, 175, 55, 0.45);
  font-size: 14px;
  text-align: center;
  min-height: 50px;
  display: flex;
  flex-wrap: wrap;
  align-items: center;
  justify-content: center;
  gap: 10px;
  backdrop-filter: blur(10px);
  opacity: 0;
  transition: opacity 0.3s;
  white-space: pre-line;
  color: #f5e6c8;
}
.text-display.show { opacity: 1; }
.play-voice-btn {
  margin-top: 4px;
  padding: 6px 14px;
  border: 1px solid rgba(212, 175, 55, 0.6);
  background: rgba(212, 175, 55, 0.2);
  color: #d4af37;
  border-radius: 20px;
  cursor: pointer;
  font-size: 13px;
}
.play-voice-btn:hover { background: rgba(212, 175, 55, 0.4); color: #f5e6c8; }
.voice-btn {
  min-width: 200px;
  padding: 14px 28px;
  border-radius: 50px;
  border: 1px solid rgba(212, 175, 55, 0.5);
  background: rgba(40, 30, 18, 0.85);
  backdrop-filter: blur(8px);
  color: #e8c547;
  font-size: 15px;
  font-family: 'Inter', sans-serif;
  font-weight: 500;
  cursor: pointer;
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 10px;
  transition: all 0.25s ease;
  box-shadow: 0 4px 20px rgba(0, 0, 0, 0.25);
}
.voice-btn:hover {
  background: rgba(212, 175, 55, 0.2);
  border-color: rgba(212, 175, 55, 0.7);
  color: #f5e6c8;
  box-shadow: 0 4px 24px rgba(212, 175, 55, 0.25);
}
.voice-btn.listening {
  background: rgba(201, 90, 58, 0.25);
  border-color: rgba(201, 90, 58, 0.6);
  color: #e8b86d;
  box-shadow: 0 4px 24px rgba(201, 90, 58, 0.3);
}
.voice-btn .mic-icon { font-size: 20px; }
.ollama-badge {
  position: absolute;
  top: 16px;
  right: 16px;
  background: rgba(212, 175, 55, 0.25);
  padding: 6px 12px;
  border-radius: 20px;
  font-size: 11px;
  border: 1px solid rgba(212, 175, 55, 0.55);
  color: #d4af37;
}

/* Hero title ‚Äì AhmedX AI */
.hero-title {
  position: absolute;
  top: 48px;
  left: 50%;
  transform: translateX(-50%);
  font-family: 'Orbitron', sans-serif;
  font-size: clamp(1rem, 4vw, 1.35rem);
  font-weight: 600;
  color: #1a1510;
  text-shadow: 0 0 20px rgba(212, 175, 55, 0.5), 0 1px 2px rgba(255, 255, 255, 0.3);
  background: linear-gradient(135deg, rgba(212, 175, 55, 0.35), rgba(232, 197, 71, 0.25));
  backdrop-filter: blur(10px);
  padding: 10px 24px;
  border-radius: 50px;
  border: 1px solid rgba(212, 175, 55, 0.5);
  letter-spacing: 0.02em;
  white-space: nowrap;
  box-shadow: 0 4px 20px rgba(0, 0, 0, 0.15);
  /* margin-top: 100px; */
}
@media (max-width: 480px) {
  .hero-title { white-space: normal; text-align: center; max-width: 90%; }
}
</style>
</head>
<body>
<header>
  <h3 class="hero-title">AhmedX AI ‚Äì your friendly assistant</h3>

</header>
<div class="container">

  <!-- 1Ô∏è‚É£ Anime character video: replace src with your 10-second (or any length) loop video -->
  <div class="video-wrap" id="videoWrap">
    <video id="avatar-video" loop muted playsinline preload="auto">
      <source src="../madni3.mp4" type="video/mp4">
    </video>
  </div>

  <!-- Audio element: used when TTS is from a URL; with SpeechSynthesis we sync video to utterance events -->
  <audio id="tts-audio" style="display:none"></audio>

  <div class="status" id="status">Hi! I'm AhmedX. Say something, I'm listening!</div>
  <div class="text-display" id="textDisplay"></div>
  <button class="voice-btn" id="voiceBtn" onclick="toggleVoice()">
    <span class="mic-icon">üé§</span>
    <span class="mic-label">Tap to speak</span>
  </button>
</div>

<script>
// ============ CONFIG: Replace these for your setup ============
const CONFIG = {
  BOT_NAME: "Ahmed",
  // Your anime character video (e.g. 10-second loop). Relative to this HTML or full URL.
  VIDEO_SRC: "../madni3.mp4",
  // Chatbot API: POST { text } ‚Üí { reply }
  BACKEND_URL: "http://127.0.0.1:8001",
  CHAT_ENDPOINT: "/chat"
};

// ============ DOM refs ============
const voiceBtn = document.getElementById("voiceBtn");
const status = document.getElementById("status");
const textDisplay = document.getElementById("textDisplay");
const avatarVideo = document.getElementById("avatar-video");
const videoWrap = document.getElementById("videoWrap");
const ttsAudio = document.getElementById("tts-audio");

// ============ State ============
let recognition = null;
let isListening = false;   // user is speaking (mic active)
let isProcessing = false;  // waiting for chatbot API
let isSpeaking = false;   // chatbot TTS is playing
let synth = window.speechSynthesis;
let lastBotReply = "";
let kidVoice = null;  // TTS voice (prefer kid/child-like)
let mouthSyncRAF = null;  // optional volume-based mouth sync animation

// ============ VIDEO CONTROL ============

/** Pause the avatar video (e.g. when user starts speaking or TTS ends). */
function pauseAvatarVideo() {
  if (!avatarVideo) return;
  avatarVideo.pause();
  videoWrap.classList.remove("talking");
  stopMouthSync();
}

/**
 * Play the avatar video and keep it in sync with TTS.
 * Video has loop=true so if TTS is longer than video length, it loops automatically.
 */
function playAvatarVideoWithTTS() {
  if (!avatarVideo) return;
  avatarVideo.loop = true;
  avatarVideo.currentTime = 0;
  avatarVideo.play().catch(function() {});
  videoWrap.classList.add("talking");
  startMouthSync();
}

// ============ 2Ô∏è‚É£ USER SPEAKING: video pauses ============
/** Called when user starts speaking (mic listening). */
function onUserStartSpeaking() {
  pauseAvatarVideo();
  isListening = true;
  status.textContent = "I'm listening... speak!";
  voiceBtn.classList.add("listening");
  const icon = voiceBtn.querySelector(".mic-icon");
  const label = voiceBtn.querySelector(".mic-label");
  if (icon) icon.textContent = "üî¥";
  if (label) label.textContent = "Listening...";
}

/** Called when user stops speaking (mic stopped). */
function onUserStopSpeaking() {
  isListening = false;
  voiceBtn.classList.remove("listening");
  const icon = voiceBtn.querySelector(".mic-icon");
  const label = voiceBtn.querySelector(".mic-label");
  if (icon) icon.textContent = "üé§";
  if (label) label.textContent = "Tap to speak";
}

// ============ 3Ô∏è‚É£ CHATBOT LISTENING / PROCESSING: video stays paused ============
/** While waiting for API response, video remains paused (no extra call needed). */

// ============ 4Ô∏è‚É£ & 5Ô∏è‚É£ CHATBOT REPLIES: video plays with TTS, stops when TTS ends ============

function showText(text, type) {
  textDisplay.innerHTML = "";
  const span = document.createElement("span");
  span.style.flex = "1 1 100%";
  span.textContent = text;
  textDisplay.appendChild(span);
  if (type === "bot") {
    lastBotReply = text;
    const btn = document.createElement("button");
    btn.type = "button";
    btn.className = "play-voice-btn";
    btn.textContent = "üîä Play";
    btn.onclick = () => speakText(lastBotReply);
    textDisplay.appendChild(btn);
  }
  textDisplay.classList.add("show");
  setTimeout(() => textDisplay.classList.remove("show"), 8000);
}

/** Pick a clear, natural TTS voice ‚Äì 10‚Äì12 saal ke larke jaisi (clear, not blur). */
function pickKidVoice() {
  const voices = synth.getVoices();
  if (!voices.length) return;
  // Pehle clear, natural English male/teen voices (blur nahi, sahih awaz)
  const clearMale = ["Microsoft David", "Daniel", "Google US English Male", "Alex", "David"];
  for (const name of clearMale) {
    const v = voices.find(x => x.name.includes(name));
    if (v) { kidVoice = v; return; }
  }
  // Phir koi bhi clear English voice
  kidVoice = voices.find(v => v.lang && v.lang.startsWith("en")) || voices[0];
}

/**
 * Speak chatbot reply via TTS and sync video:
 * - On TTS start: play video (loop so long TTS is covered).
 * - On TTS end: pause video. Ensures proper sync between video and audio.
 */
function speakText(text) {
  if (!text || !text.trim()) return;
  try {
    synth.cancel();
    pauseAvatarVideo();
  } catch (e) {}

  isSpeaking = true;
  status.textContent = CONFIG.BOT_NAME + " is talking...";
  showText(text, "bot");
  if (synth.resume) synth.resume();

  const utterance = new SpeechSynthesisUtterance(text);
  utterance.lang = "en-US";
  utterance.rate = 1.0;      // Normal speed ‚Äì clear, blur nahi
  utterance.pitch = 1.2;     // Thora high = 10‚Äì12 saal ke larke jaisi, natural (1.55 se kam = sahih awaz)
  utterance.volume = 1.0;
  if (kidVoice) utterance.voice = kidVoice;

  // 4Ô∏è‚É£ When TTS starts, play video (with loop) so video and audio run together.
  utterance.onstart = function() {
    playAvatarVideoWithTTS();
  };

  // 5Ô∏è‚É£ When TTS ends, pause video so it stays in sync with audio.
  utterance.onend = function() {
    isSpeaking = false;
    pauseAvatarVideo();
    status.textContent = "Tap mic to talk to " + CONFIG.BOT_NAME + "!";
    try {
      setTimeout(function() {
        if (!isListening && recognition) {
          status.textContent = "Say something to " + CONFIG.BOT_NAME + "!";
          recognition.start();
        }
      }, 300);
    } catch (err) {}
  };

  utterance.onerror = function() {
    isSpeaking = false;
    pauseAvatarVideo();
    status.textContent = "Tap mic to talk to me!";
  };

  synth.speak(utterance);
}

// ============ 8Ô∏è‚É£ OPTIONAL: Simple mouth sync to TTS ‚Äúvolume‚Äù (visual pulse) ============
/** Uses requestAnimationFrame to drive a visual ‚Äútalking‚Äù effect (e.g. glow). For real mouth sync you‚Äôd need an avatar with mouth params (e.g. Live2D) and audio analysis. */
function startMouthSync() {
  if (mouthSyncRAF) return;
  let t = 0;
  function tick() {
    if (!isSpeaking || !videoWrap) {
      mouthSyncRAF = null;
      return;
    }
    t += 0.15;
    // Simple periodic intensity (no real volume here; would need Web Audio + AnalyserNode for that).
    const intensity = 0.3 + 0.25 * Math.abs(Math.sin(t));
    videoWrap.style.boxShadow = "0 0 " + (20 + intensity * 30) + "px rgba(212, 175, 55, " + intensity + ")";
    mouthSyncRAF = requestAnimationFrame(tick);
  }
  mouthSyncRAF = requestAnimationFrame(tick);
}

function stopMouthSync() {
  if (mouthSyncRAF) {
    cancelAnimationFrame(mouthSyncRAF);
    mouthSyncRAF = null;
  }
  if (videoWrap) videoWrap.style.boxShadow = "";
}

// ============ MIC / RECOGNITION ============
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
if (SpeechRecognition) {
  recognition = new SpeechRecognition();
  recognition.continuous = false;
  recognition.interimResults = false;
  recognition.lang = "en-US";

  // 2Ô∏è‚É£ User starts speaking ‚Üí pause video
  recognition.onstart = function() {
    onUserStartSpeaking();
  };

  recognition.onresult = function(e) {
    const transcript = e.results[0][0].transcript;
    status.textContent = "Got it!";
    showText(transcript, "user");
    onUserStopSpeaking();
    setTimeout(function() { sendMessage(transcript); }, 400);
  };

  recognition.onerror = function() {
    onUserStopSpeaking();
    status.textContent = "Couldn't hear. Try again!";
    setTimeout(function() { status.textContent = "Tap mic to talk to me!"; }, 2000);
  };

  recognition.onend = function() {
    onUserStopSpeaking();
    if (!isSpeaking) status.textContent = "Tap mic to talk to " + CONFIG.BOT_NAME + "!";
  };

  synth.addEventListener("voiceschanged", pickKidVoice);
  setTimeout(pickKidVoice, 500);
} else {
  status.textContent = "Voice not supported. Use Chrome or Edge.";
}

function toggleVoice() {
  if (!recognition) return;
  if (isListening) {
    recognition.stop();
  } else {
    // Jab user mic pe click kare aur bot bol raha ho ‚Äì turant chup karo, phir listen
    if (isSpeaking) {
      isSpeaking = false;
      try { synth.cancel(); } catch (e) {}
      pauseAvatarVideo();
      status.textContent = "Listening...";
      setTimeout(function() {
        if (!recognition) return;
        recognition.start();
      }, 150);
      return;
    }
    recognition.start();
  }
}

// ============ CHATBOT API ============
/** 3Ô∏è‚É£ Chatbot listens: we show ‚ÄúGetting answer‚Ä¶‚Äù and call API. Video stays paused until TTS starts. */
async function sendMessage(text) {
  isProcessing = true;
  status.textContent = "Thinking...";
  pauseAvatarVideo();

  try {
    const res = await fetch(CONFIG.BACKEND_URL + CONFIG.CHAT_ENDPOINT, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ text: text })
    });
    const data = await res.json();
    isProcessing = false;

    if (data.reply && !data.reply.startsWith("‚ùå") && !data.reply.startsWith("‚è≥")) {
      lastBotReply = data.reply;
      status.textContent = CONFIG.BOT_NAME + " is talking...";
      speakText(data.reply);
    } else {
      status.textContent = data.reply || "Oops!";
      status.classList.add("error");
      showText(data.reply || "Error", "error");
      setTimeout(function() {
        status.classList.remove("error");
        status.textContent = "Tap mic to talk to me!";
      }, 5000);
    }
  } catch (err) {
    isProcessing = false;
    status.textContent = "I can't reach the server...";
    status.classList.add("error");
    showText("Backend offline. Start backend on port 8001.", "error");
    setTimeout(function() {
      status.classList.remove("error");
      status.textContent = "Tap mic to talk to me!";
    }, 5000);
  }
}

// ============ INIT ============
document.addEventListener("DOMContentLoaded", function() {
  if (CONFIG.VIDEO_SRC && avatarVideo) {
    const src = avatarVideo.querySelector("source");
    if (src) src.src = CONFIG.VIDEO_SRC;
  }
  status.textContent = "Hi! I'm " + CONFIG.BOT_NAME + ". Say something, I'm listening!";
});
</script>

</body>
</html>
